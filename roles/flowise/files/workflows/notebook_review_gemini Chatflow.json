{
  "nodes": [
    {
      "width": 300,
      "height": 547,
      "id": "promptTemplate_0",
      "position": {
        "x": -372.985172495504,
        "y": -191.02575607289208
      },
      "type": "customNode",
      "data": {
        "id": "promptTemplate_0",
        "label": "Prompt Template",
        "version": 1,
        "name": "promptTemplate",
        "type": "PromptTemplate",
        "baseClasses": [
          "PromptTemplate",
          "BaseStringPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a basic prompt for an LLM",
        "inputParams": [
          {
            "label": "Template",
            "name": "template",
            "type": "string",
            "rows": 4,
            "placeholder": "What is a good name for a company that makes {product}?",
            "id": "promptTemplate_0-input-template-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "promptTemplate_0-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "template": "Correlate functional, generative, cognitive and pragmatic grammars to then rephrase the question adding specificity. Make note if the dependent clause is not in the correct form. \n\n{question}",
          "promptValues": "{\"question\":\"{{question}}\",\"chat_history\":\"{{chat_history}}\"}"
        },
        "outputAnchors": [
          {
            "id": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
            "name": "promptTemplate",
            "label": "PromptTemplate",
            "type": "PromptTemplate | BaseStringPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": -372.985172495504,
        "y": -191.02575607289208
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 724,
      "id": "chatPromptTemplate_0",
      "position": {
        "x": 1759.803349919375,
        "y": -371.3772618338048
      },
      "type": "customNode",
      "data": {
        "id": "chatPromptTemplate_0",
        "label": "Chat Prompt Template",
        "version": 1,
        "name": "chatPromptTemplate",
        "type": "ChatPromptTemplate",
        "baseClasses": [
          "ChatPromptTemplate",
          "BaseChatPromptTemplate",
          "BasePromptTemplate",
          "Runnable"
        ],
        "category": "Prompts",
        "description": "Schema to represent a chat prompt",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessagePrompt",
            "type": "string",
            "rows": 4,
            "placeholder": "You are a helpful assistant that translates {input_language} to {output_language}.",
            "id": "chatPromptTemplate_0-input-systemMessagePrompt-string"
          },
          {
            "label": "Human Message",
            "name": "humanMessagePrompt",
            "type": "string",
            "rows": 4,
            "placeholder": "{text}",
            "id": "chatPromptTemplate_0-input-humanMessagePrompt-string"
          },
          {
            "label": "Format Prompt Values",
            "name": "promptValues",
            "type": "json",
            "optional": true,
            "acceptVariable": true,
            "list": true,
            "id": "chatPromptTemplate_0-input-promptValues-json"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "systemMessagePrompt": "Using the provided context, answer the user's question to the best of your ability using the resources provided. If there is nothing in the context relevant to the question at hand, ask for clarification.\n\nAnything between the following \\`context\\`  html blocks is retrieved from a knowledge bank, not part of the conversation with the user.\n\n<context>\n    {context}\n<context/>\n\nREMEMBER: If there is no relevant information within the context, just ask \"Can you elaborate?\" Don't try to make up an answer. Anything between the preceding 'context' html blocks is retrieved from a knowledge bank, not part of the conversation with the user.",
          "humanMessagePrompt": "{text}",
          "promptValues": "{\"context\":\"{{vectorStoreToDocument_0.data.instance}}\",\"text\":\"{{question}}\"}"
        },
        "outputAnchors": [
          {
            "id": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
            "name": "chatPromptTemplate",
            "label": "ChatPromptTemplate",
            "type": "ChatPromptTemplate | BaseChatPromptTemplate | BasePromptTemplate | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 1759.803349919375,
        "y": -371.3772618338048
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 495,
      "id": "vectorStoreToDocument_0",
      "position": {
        "x": 1120.1074408207946,
        "y": -366.38840514980575
      },
      "type": "customNode",
      "data": {
        "id": "vectorStoreToDocument_0",
        "label": "VectorStore To Document",
        "version": 2,
        "name": "vectorStoreToDocument",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Search documents with scores from vector store",
        "inputParams": [
          {
            "label": "Query",
            "name": "query",
            "type": "string",
            "description": "Query to retrieve documents from vector database. If not specified, user question will be used",
            "optional": true,
            "acceptVariable": true,
            "id": "vectorStoreToDocument_0-input-query-string"
          },
          {
            "label": "Minimum Score (%)",
            "name": "minScore",
            "type": "number",
            "optional": true,
            "placeholder": "75",
            "step": 1,
            "description": "Minumum score for embeddings documents to be included",
            "id": "vectorStoreToDocument_0-input-minScore-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Vector Store",
            "name": "vectorStore",
            "type": "VectorStore",
            "id": "vectorStoreToDocument_0-input-vectorStore-VectorStore"
          }
        ],
        "inputs": {
          "vectorStore": "{{chroma_0.data.instance}}",
          "query": "{{llmChain_2.data.instance}}",
          "minScore": "20"
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "options": [
              {
                "id": "vectorStoreToDocument_0-output-document-Document|json",
                "name": "document",
                "label": "Document",
                "type": "Document | json"
              },
              {
                "id": "vectorStoreToDocument_0-output-text-string|json",
                "name": "text",
                "label": "Text",
                "type": "string | json"
              }
            ],
            "default": "document"
          }
        ],
        "outputs": {
          "output": "text"
        },
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 1120.1074408207946,
        "y": -366.38840514980575
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 553,
      "id": "llmChain_2",
      "position": {
        "x": 295.8049400095758,
        "y": -356.59102093770093
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_2",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_2-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_2-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_2-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_2-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_2-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{cohere_0.data.instance}}",
          "prompt": "{{promptTemplate_0.data.instance}}",
          "outputParser": "",
          "chainName": "RephraseQuestion",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "options": [
              {
                "id": "llmChain_2-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_2-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "outputPrediction"
        },
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 295.8049400095758,
        "y": -356.59102093770093
      },
      "dragging": false
    },
    {
      "width": 300,
      "height": 553,
      "id": "llmChain_1",
      "position": {
        "x": 2410.8348541843116,
        "y": -806.1875704643429
      },
      "type": "customNode",
      "data": {
        "id": "llmChain_1",
        "label": "LLM Chain",
        "version": 3,
        "name": "llmChain",
        "type": "LLMChain",
        "baseClasses": [
          "LLMChain",
          "BaseChain",
          "Runnable"
        ],
        "category": "Chains",
        "description": "Chain to run queries against LLMs",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "chainName",
            "type": "string",
            "placeholder": "Name Your Chain",
            "optional": true,
            "id": "llmChain_1-input-chainName-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Language Model",
            "name": "model",
            "type": "BaseLanguageModel",
            "id": "llmChain_1-input-model-BaseLanguageModel"
          },
          {
            "label": "Prompt",
            "name": "prompt",
            "type": "BasePromptTemplate",
            "id": "llmChain_1-input-prompt-BasePromptTemplate"
          },
          {
            "label": "Output Parser",
            "name": "outputParser",
            "type": "BaseLLMOutputParser",
            "optional": true,
            "id": "llmChain_1-input-outputParser-BaseLLMOutputParser"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "llmChain_1-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "model": "{{groqChat_0.data.instance}}",
          "prompt": "{{chatPromptTemplate_0.data.instance}}",
          "outputParser": "",
          "chainName": "FinalResponse",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "options": [
              {
                "id": "llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable",
                "name": "llmChain",
                "label": "LLM Chain",
                "type": "LLMChain | BaseChain | Runnable"
              },
              {
                "id": "llmChain_1-output-outputPrediction-string|json",
                "name": "outputPrediction",
                "label": "Output Prediction",
                "type": "string | json"
              }
            ],
            "default": "llmChain"
          }
        ],
        "outputs": {
          "output": "outputPrediction"
        },
        "selected": false
      },
      "selected": false,
      "positionAbsolute": {
        "x": 2410.8348541843116,
        "y": -806.1875704643429
      },
      "dragging": false
    },
    {
      "id": "chroma_0",
      "position": {
        "x": 1204.3446370850083,
        "y": -2468.5926215285963
      },
      "type": "customNode",
      "data": {
        "id": "chroma_0",
        "label": "Chroma",
        "version": 2,
        "name": "chroma",
        "type": "Chroma",
        "baseClasses": [
          "Chroma",
          "VectorStoreRetriever",
          "BaseRetriever"
        ],
        "category": "Vector Stores",
        "description": "Upsert embedded data and perform similarity search upon query using Chroma, an open-source embedding database",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "description": "Only needed if you have chroma on cloud services with X-Api-key",
            "optional": true,
            "credentialNames": [
              "chromaApi"
            ],
            "id": "chroma_0-input-credential-credential"
          },
          {
            "label": "Collection Name",
            "name": "collectionName",
            "type": "string",
            "id": "chroma_0-input-collectionName-string"
          },
          {
            "label": "Chroma URL",
            "name": "chromaURL",
            "type": "string",
            "optional": true,
            "id": "chroma_0-input-chromaURL-string"
          },
          {
            "label": "Chroma Metadata Filter",
            "name": "chromaMetadataFilter",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "chroma_0-input-chromaMetadataFilter-json"
          },
          {
            "label": "Top K",
            "name": "topK",
            "description": "Number of top results to fetch. Default to 4",
            "placeholder": "4",
            "type": "number",
            "additionalParams": true,
            "optional": true,
            "id": "chroma_0-input-topK-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Document",
            "name": "document",
            "type": "Document",
            "list": true,
            "optional": true,
            "id": "chroma_0-input-document-Document"
          },
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "chroma_0-input-embeddings-Embeddings"
          },
          {
            "label": "Record Manager",
            "name": "recordManager",
            "type": "RecordManager",
            "description": "Keep track of the record to prevent duplication",
            "optional": true,
            "id": "chroma_0-input-recordManager-RecordManager"
          }
        ],
        "inputs": {
          "document": [
            "{{cheerioWebScraper_0.data.instance}}"
          ],
          "embeddings": "{{redisEmbeddingsCache_0.data.instance}}",
          "recordManager": "",
          "collectionName": "syncopated",
          "chromaURL": "http://ninjabot:8000",
          "chromaMetadataFilter": "",
          "topK": ""
        },
        "outputAnchors": [
          {
            "name": "output",
            "label": "Output",
            "type": "options",
            "description": "",
            "options": [
              {
                "id": "chroma_0-output-retriever-Chroma|VectorStoreRetriever|BaseRetriever",
                "name": "retriever",
                "label": "Chroma Retriever",
                "description": "",
                "type": "Chroma | VectorStoreRetriever | BaseRetriever"
              },
              {
                "id": "chroma_0-output-vectorStore-Chroma|VectorStore",
                "name": "vectorStore",
                "label": "Chroma Vector Store",
                "description": "",
                "type": "Chroma | VectorStore"
              }
            ],
            "default": "retriever"
          }
        ],
        "outputs": {
          "output": "vectorStore"
        },
        "selected": false
      },
      "width": 300,
      "height": 771,
      "positionAbsolute": {
        "x": 1204.3446370850083,
        "y": -2468.5926215285963
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "redisEmbeddingsCache_0",
      "position": {
        "x": 665.7018606465967,
        "y": -2283.463721071832
      },
      "type": "customNode",
      "data": {
        "id": "redisEmbeddingsCache_0",
        "label": "Redis Embeddings Cache",
        "version": 1,
        "name": "redisEmbeddingsCache",
        "type": "RedisEmbeddingsCache",
        "baseClasses": [
          "RedisEmbeddingsCache",
          "Embeddings"
        ],
        "category": "Cache",
        "description": "Cache generated Embeddings in Redis to avoid needing to recompute them.",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "optional": true,
            "credentialNames": [
              "redisCacheApi",
              "redisCacheUrlApi"
            ],
            "id": "redisEmbeddingsCache_0-input-credential-credential"
          },
          {
            "label": "Time to Live (ms)",
            "name": "ttl",
            "type": "number",
            "step": 10,
            "default": 3600,
            "optional": true,
            "additionalParams": true,
            "id": "redisEmbeddingsCache_0-input-ttl-number"
          },
          {
            "label": "Namespace",
            "name": "namespace",
            "type": "string",
            "optional": true,
            "additionalParams": true,
            "id": "redisEmbeddingsCache_0-input-namespace-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Embeddings",
            "name": "embeddings",
            "type": "Embeddings",
            "id": "redisEmbeddingsCache_0-input-embeddings-Embeddings"
          }
        ],
        "inputs": {
          "embeddings": "{{googleGenerativeAiEmbeddings_0.data.instance}}",
          "ttl": 3600,
          "namespace": ""
        },
        "outputAnchors": [
          {
            "id": "redisEmbeddingsCache_0-output-redisEmbeddingsCache-RedisEmbeddingsCache|Embeddings",
            "name": "redisEmbeddingsCache",
            "label": "RedisEmbeddingsCache",
            "description": "Cache generated Embeddings in Redis to avoid needing to recompute them.",
            "type": "RedisEmbeddingsCache | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 416,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 665.7018606465967,
        "y": -2283.463721071832
      }
    },
    {
      "id": "chainTool_0",
      "position": {
        "x": 3097.5543997587124,
        "y": -556.0073618404447
      },
      "type": "customNode",
      "data": {
        "id": "chainTool_0",
        "label": "Chain Tool",
        "version": 1,
        "name": "chainTool",
        "type": "ChainTool",
        "baseClasses": [
          "ChainTool",
          "DynamicTool",
          "Tool",
          "StructuredTool",
          "Runnable"
        ],
        "category": "Tools",
        "description": "Use a chain as allowed tool for agent",
        "inputParams": [
          {
            "label": "Chain Name",
            "name": "name",
            "type": "string",
            "placeholder": "state-of-union-qa",
            "id": "chainTool_0-input-name-string"
          },
          {
            "label": "Chain Description",
            "name": "description",
            "type": "string",
            "rows": 3,
            "placeholder": "State of the Union QA - useful for when you need to ask questions about the most recent state of the union address.",
            "id": "chainTool_0-input-description-string"
          },
          {
            "label": "Return Direct",
            "name": "returnDirect",
            "type": "boolean",
            "optional": true,
            "id": "chainTool_0-input-returnDirect-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Base Chain",
            "name": "baseChain",
            "type": "BaseChain",
            "id": "chainTool_0-input-baseChain-BaseChain"
          }
        ],
        "inputs": {
          "name": "knowledgebase",
          "description": "Knowledge Base - Useful for gathering specific information",
          "returnDirect": false,
          "baseChain": "{{llmChain_1.data.instance}}"
        },
        "outputAnchors": [
          {
            "id": "chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
            "name": "chainTool",
            "label": "ChainTool",
            "description": "Use a chain as allowed tool for agent",
            "type": "ChainTool | DynamicTool | Tool | StructuredTool | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 638,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 3097.5543997587124,
        "y": -556.0073618404447
      }
    },
    {
      "id": "RedisBackedChatMemory_0",
      "position": {
        "x": 3072.334239458466,
        "y": 321.69593205396774
      },
      "type": "customNode",
      "data": {
        "id": "RedisBackedChatMemory_0",
        "label": "Redis-Backed Chat Memory",
        "version": 2,
        "name": "RedisBackedChatMemory",
        "type": "RedisBackedChatMemory",
        "baseClasses": [
          "RedisBackedChatMemory",
          "BaseChatMemory",
          "BaseMemory"
        ],
        "category": "Memory",
        "description": "Summarizes the conversation and stores the memory in Redis server",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "optional": true,
            "credentialNames": [
              "redisCacheApi",
              "redisCacheUrlApi"
            ],
            "id": "RedisBackedChatMemory_0-input-credential-credential"
          },
          {
            "label": "Session Id",
            "name": "sessionId",
            "type": "string",
            "description": "If not specified, a random id will be used. Learn <a target=\"_blank\" href=\"https://docs.flowiseai.com/memory/long-term-memory#ui-and-embedded-chat\">more</a>",
            "default": "",
            "additionalParams": true,
            "optional": true,
            "id": "RedisBackedChatMemory_0-input-sessionId-string"
          },
          {
            "label": "Session Timeouts",
            "name": "sessionTTL",
            "type": "number",
            "description": "Omit this parameter to make sessions never expire",
            "additionalParams": true,
            "optional": true,
            "id": "RedisBackedChatMemory_0-input-sessionTTL-number"
          },
          {
            "label": "Memory Key",
            "name": "memoryKey",
            "type": "string",
            "default": "chat_history",
            "additionalParams": true,
            "id": "RedisBackedChatMemory_0-input-memoryKey-string"
          },
          {
            "label": "Window Size",
            "name": "windowSize",
            "type": "number",
            "description": "Window of size k to surface the last k back-and-forth to use as memory.",
            "additionalParams": true,
            "optional": true,
            "id": "RedisBackedChatMemory_0-input-windowSize-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "sessionId": "",
          "sessionTTL": "",
          "memoryKey": "chat_history",
          "windowSize": ""
        },
        "outputAnchors": [
          {
            "id": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
            "name": "RedisBackedChatMemory",
            "label": "RedisBackedChatMemory",
            "description": "Summarizes the conversation and stores the memory in Redis server",
            "type": "RedisBackedChatMemory | BaseChatMemory | BaseMemory"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 361,
      "selected": false,
      "positionAbsolute": {
        "x": 3072.334239458466,
        "y": 321.69593205396774
      },
      "dragging": false
    },
    {
      "id": "redisCache_0",
      "position": {
        "x": 1967.7220719513066,
        "y": 629.7573057402429
      },
      "type": "customNode",
      "data": {
        "id": "redisCache_0",
        "label": "Redis Cache",
        "version": 1,
        "name": "redisCache",
        "type": "RedisCache",
        "baseClasses": [
          "RedisCache",
          "BaseCache"
        ],
        "category": "Cache",
        "description": "Cache LLM response in Redis, useful for sharing cache across multiple processes or servers",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "optional": true,
            "credentialNames": [
              "redisCacheApi",
              "redisCacheUrlApi"
            ],
            "id": "redisCache_0-input-credential-credential"
          },
          {
            "label": "Time to Live (ms)",
            "name": "ttl",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "redisCache_0-input-ttl-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "ttl": ""
        },
        "outputAnchors": [
          {
            "id": "redisCache_0-output-redisCache-RedisCache|BaseCache",
            "name": "redisCache",
            "label": "RedisCache",
            "description": "Cache LLM response in Redis, useful for sharing cache across multiple processes or servers",
            "type": "RedisCache | BaseCache"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 361,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 1967.7220719513066,
        "y": 629.7573057402429
      }
    },
    {
      "id": "googleGenerativeAiEmbeddings_0",
      "position": {
        "x": -398.1851967043857,
        "y": -1598.7463169976866
      },
      "type": "customNode",
      "data": {
        "id": "googleGenerativeAiEmbeddings_0",
        "label": "GoogleGenerativeAI Embeddings",
        "version": 2,
        "name": "googleGenerativeAiEmbeddings",
        "type": "GoogleGenerativeAiEmbeddings",
        "baseClasses": [
          "GoogleGenerativeAiEmbeddings",
          "Embeddings"
        ],
        "category": "Embeddings",
        "description": "Google Generative API to generate embeddings for a given text",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "googleGenerativeAiEmbeddings_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "embedding-001",
            "id": "googleGenerativeAiEmbeddings_0-input-modelName-asyncOptions"
          },
          {
            "label": "Task Type",
            "name": "tasktype",
            "type": "options",
            "description": "Type of task for which the embedding will be used",
            "options": [
              {
                "label": "TASK_TYPE_UNSPECIFIED",
                "name": "TASK_TYPE_UNSPECIFIED"
              },
              {
                "label": "RETRIEVAL_QUERY",
                "name": "RETRIEVAL_QUERY"
              },
              {
                "label": "RETRIEVAL_DOCUMENT",
                "name": "RETRIEVAL_DOCUMENT"
              },
              {
                "label": "SEMANTIC_SIMILARITY",
                "name": "SEMANTIC_SIMILARITY"
              },
              {
                "label": "CLASSIFICATION",
                "name": "CLASSIFICATION"
              },
              {
                "label": "CLUSTERING",
                "name": "CLUSTERING"
              }
            ],
            "default": "TASK_TYPE_UNSPECIFIED",
            "id": "googleGenerativeAiEmbeddings_0-input-tasktype-options"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "modelName": "embedding-001",
          "tasktype": "RETRIEVAL_DOCUMENT"
        },
        "outputAnchors": [
          {
            "id": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
            "name": "googleGenerativeAiEmbeddings",
            "label": "GoogleGenerativeAiEmbeddings",
            "description": "Google Generative API to generate embeddings for a given text",
            "type": "GoogleGenerativeAiEmbeddings | Embeddings"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 512,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -398.1851967043857,
        "y": -1598.7463169976866
      }
    },
    {
      "id": "redisCache_1",
      "position": {
        "x": 2428.1189708949205,
        "y": -2663.0890806525185
      },
      "type": "customNode",
      "data": {
        "id": "redisCache_1",
        "label": "Redis Cache",
        "version": 1,
        "name": "redisCache",
        "type": "RedisCache",
        "baseClasses": [
          "RedisCache",
          "BaseCache"
        ],
        "category": "Cache",
        "description": "Cache LLM response in Redis, useful for sharing cache across multiple processes or servers",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "optional": true,
            "credentialNames": [
              "redisCacheApi",
              "redisCacheUrlApi"
            ],
            "id": "redisCache_1-input-credential-credential"
          },
          {
            "label": "Time to Live (ms)",
            "name": "ttl",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "redisCache_1-input-ttl-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "ttl": ""
        },
        "outputAnchors": [
          {
            "id": "redisCache_1-output-redisCache-RedisCache|BaseCache",
            "name": "redisCache",
            "label": "RedisCache",
            "description": "Cache LLM response in Redis, useful for sharing cache across multiple processes or servers",
            "type": "RedisCache | BaseCache"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 361,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2428.1189708949205,
        "y": -2663.0890806525185
      }
    },
    {
      "id": "groqChat_0",
      "position": {
        "x": 2328.739806033609,
        "y": -2098.538855568142
      },
      "type": "customNode",
      "data": {
        "id": "groqChat_0",
        "label": "GroqChat",
        "version": 3,
        "name": "groqChat",
        "type": "GroqChat",
        "baseClasses": [
          "GroqChat",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Groq API with LPU Inference Engine",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "groqApi"
            ],
            "optional": true,
            "id": "groqChat_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "placeholder": "llama3-70b-8192",
            "id": "groqChat_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "groqChat_0-input-temperature-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "groqChat_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "{{redisCache_1.data.instance}}",
          "modelName": "mixtral-8x7b-32768",
          "temperature": "0.4"
        },
        "outputAnchors": [
          {
            "id": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "groqChat",
            "label": "GroqChat",
            "description": "Wrapper around Groq API with LPU Inference Engine",
            "type": "GroqChat | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 571,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 2328.739806033609,
        "y": -2098.538855568142
      }
    },
    {
      "id": "cheerioWebScraper_0",
      "position": {
        "x": 436.38620334216523,
        "y": -2841.741090942946
      },
      "type": "customNode",
      "data": {
        "id": "cheerioWebScraper_0",
        "label": "Cheerio Web Scraper",
        "version": 1.1,
        "name": "cheerioWebScraper",
        "type": "Document",
        "baseClasses": [
          "Document"
        ],
        "category": "Document Loaders",
        "description": "Load data from webpages",
        "inputParams": [
          {
            "label": "URL",
            "name": "url",
            "type": "string",
            "id": "cheerioWebScraper_0-input-url-string"
          },
          {
            "label": "Get Relative Links Method",
            "name": "relativeLinksMethod",
            "type": "options",
            "description": "Select a method to retrieve relative links",
            "options": [
              {
                "label": "Web Crawl",
                "name": "webCrawl",
                "description": "Crawl relative links from HTML URL"
              },
              {
                "label": "Scrape XML Sitemap",
                "name": "scrapeXMLSitemap",
                "description": "Scrape relative links from XML sitemap URL"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "cheerioWebScraper_0-input-relativeLinksMethod-options"
          },
          {
            "label": "Get Relative Links Limit",
            "name": "limit",
            "type": "number",
            "optional": true,
            "default": "10",
            "additionalParams": true,
            "description": "Only used when \"Get Relative Links Method\" is selected. Set 0 to retrieve all relative links, default limit is 10.",
            "warning": "Retrieving all links might take long time, and all links will be upserted again if the flow's state changed (eg: different URL, chunk size, etc)",
            "id": "cheerioWebScraper_0-input-limit-number"
          },
          {
            "label": "Selector (CSS)",
            "name": "selector",
            "type": "string",
            "description": "Specify a CSS selector to select the content to be extracted",
            "optional": true,
            "additionalParams": true,
            "id": "cheerioWebScraper_0-input-selector-string"
          },
          {
            "label": "Metadata",
            "name": "metadata",
            "type": "json",
            "optional": true,
            "additionalParams": true,
            "id": "cheerioWebScraper_0-input-metadata-json"
          }
        ],
        "inputAnchors": [
          {
            "label": "Text Splitter",
            "name": "textSplitter",
            "type": "TextSplitter",
            "optional": true,
            "id": "cheerioWebScraper_0-input-textSplitter-TextSplitter"
          }
        ],
        "inputs": {
          "url": "https://b08x.github.io",
          "textSplitter": "{{htmlToMarkdownTextSplitter_0.data.instance}}",
          "relativeLinksMethod": "webCrawl",
          "limit": "41",
          "selector": "",
          "metadata": "",
          "selectedLinks": [
            "https://b08x.github.io",
            "https://b08x.github.io/metaprompt",
            "https://b08x.github.io/flowise-langfuse-anthropic-gemini",
            "https://b08x.github.io/about",
            "https://b08x.github.io/data-driven-characters/The-Database-and-the-Narrative",
            "https://b08x.github.io/data-driven-characters/www.google.com",
            "https://b08x.github.io/gitflow",
            "https://b08x.github.io/ruby/Using-the-Iterator-Design-Pattern",
            "https://b08x.github.io/ruby/Using-NLP-to-Generate-Music",
            "https://b08x.github.io/ruby/Unless",
            "https://b08x.github.io/A-Recipe-for-Generative-Music",
            "https://b08x.github.io/ruby/Ruby-NLP-Gems",
            "https://b08x.github.io/text-processing/Semantic-Search",
            "https://b08x.github.io/text-processing/Parts-of-a-Document",
            "https://b08x.github.io/prompt-engineering/Reasoning-Scratchpad",
            "https://b08x.github.io/llm/raggar/Ontology-Construction",
            "https://b08x.github.io/nlp/JupyterLabs-&-Ruby-NLP",
            "https://b08x.github.io/nlp/githubrepo",
            "https://b08x.github.io/nlp/Nuances",
            "https://b08x.github.io/nlp/Text-Processing",
            "https://b08x.github.io/NLP",
            "https://b08x.github.io/prompt-engineering/AgileBloom",
            "https://b08x.github.io/anthropic-metaprompt",
            "https://b08x.github.io/nlp/Attributive-Noun",
            "https://b08x.github.io/tag/grammar",
            "https://b08x.github.io/nlp/Persons",
            "https://b08x.github.io/Audio-Engineer",
            "https://b08x.github.io/text-processing/Capturing-Personality-with-Verb-Phrase-Extraction",
            "https://b08x.github.io/prompt-engineering/Character-Sheet",
            "https://b08x.github.io/text-processing/Chunk-Analyzer",
            "https://b08x.github.io/Clinical-psychologist"
          ]
        },
        "outputAnchors": [
          {
            "id": "cheerioWebScraper_0-output-cheerioWebScraper-Document",
            "name": "cheerioWebScraper",
            "label": "Document",
            "description": "Load data from webpages",
            "type": "Document"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 470,
      "positionAbsolute": {
        "x": 436.38620334216523,
        "y": -2841.741090942946
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "htmlToMarkdownTextSplitter_0",
      "position": {
        "x": -45.656066629099286,
        "y": -2436.619528021727
      },
      "type": "customNode",
      "data": {
        "id": "htmlToMarkdownTextSplitter_0",
        "label": "HtmlToMarkdown Text Splitter",
        "version": 1,
        "name": "htmlToMarkdownTextSplitter",
        "type": "HtmlToMarkdownTextSplitter",
        "baseClasses": [
          "HtmlToMarkdownTextSplitter",
          "MarkdownTextSplitter",
          "RecursiveCharacterTextSplitter",
          "TextSplitter",
          "BaseDocumentTransformer",
          "Runnable"
        ],
        "category": "Text Splitters",
        "description": "Converts Html to Markdown and then split your content into documents based on the Markdown headers",
        "inputParams": [
          {
            "label": "Chunk Size",
            "name": "chunkSize",
            "type": "number",
            "default": 1000,
            "optional": true,
            "id": "htmlToMarkdownTextSplitter_0-input-chunkSize-number"
          },
          {
            "label": "Chunk Overlap",
            "name": "chunkOverlap",
            "type": "number",
            "optional": true,
            "id": "htmlToMarkdownTextSplitter_0-input-chunkOverlap-number"
          }
        ],
        "inputAnchors": [],
        "inputs": {
          "chunkSize": "400",
          "chunkOverlap": "20"
        },
        "outputAnchors": [
          {
            "id": "htmlToMarkdownTextSplitter_0-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
            "name": "htmlToMarkdownTextSplitter",
            "label": "HtmlToMarkdownTextSplitter",
            "description": "Converts Html to Markdown and then split your content into documents based on the Markdown headers",
            "type": "HtmlToMarkdownTextSplitter | MarkdownTextSplitter | RecursiveCharacterTextSplitter | TextSplitter | BaseDocumentTransformer | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 413,
      "positionAbsolute": {
        "x": -45.656066629099286,
        "y": -2436.619528021727
      },
      "selected": false,
      "dragging": false
    },
    {
      "id": "xmlAgent_0",
      "position": {
        "x": 4451.735047073274,
        "y": 191.84955995995517
      },
      "type": "customNode",
      "data": {
        "id": "xmlAgent_0",
        "label": "XML Agent",
        "version": 2,
        "name": "xmlAgent",
        "type": "XMLAgent",
        "baseClasses": [
          "XMLAgent",
          "BaseChain",
          "Runnable"
        ],
        "category": "Agents",
        "description": "Agent that is designed for LLMs that are good for reasoning/writing XML (e.g: Anthropic Claude)",
        "inputParams": [
          {
            "label": "System Message",
            "name": "systemMessage",
            "type": "string",
            "warning": "Prompt must include input variables: {tools}, {chat_history}, {input} and {agent_scratchpad}",
            "rows": 4,
            "default": "You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}",
            "additionalParams": true,
            "id": "xmlAgent_0-input-systemMessage-string"
          }
        ],
        "inputAnchors": [
          {
            "label": "Tools",
            "name": "tools",
            "type": "Tool",
            "list": true,
            "id": "xmlAgent_0-input-tools-Tool"
          },
          {
            "label": "Memory",
            "name": "memory",
            "type": "BaseChatMemory",
            "id": "xmlAgent_0-input-memory-BaseChatMemory"
          },
          {
            "label": "Chat Model",
            "name": "model",
            "type": "BaseChatModel",
            "id": "xmlAgent_0-input-model-BaseChatModel"
          },
          {
            "label": "Input Moderation",
            "description": "Detect text that could generate harmful output and prevent it from being sent to the language model",
            "name": "inputModeration",
            "type": "Moderation",
            "optional": true,
            "list": true,
            "id": "xmlAgent_0-input-inputModeration-Moderation"
          }
        ],
        "inputs": {
          "tools": [
            "{{chainTool_0.data.instance}}"
          ],
          "memory": "{{RedisBackedChatMemory_0.data.instance}}",
          "model": "{{chatGoogleGenerativeAI_0.data.instance}}",
          "systemMessage": "You are a helpful assistant. Help the user answer any questions.\n\nYou have access to the following tools:\n\n{tools}\n\nIn order to use a tool, you can use <tool></tool> and <tool_input></tool_input> tags. You will then get back a response in the form <observation></observation>\nFor example, if you have a tool called 'search' that could run a google search, in order to search for the weather in SF you would respond:\n\n<tool>search</tool><tool_input>weather in SF</tool_input>\n<observation>64 degrees</observation>\n\nWhen you are done, respond with a final answer between <final_answer></final_answer>. For example:\n\n<final_answer>The weather in SF is 64 degrees</final_answer>\n\nBegin!\n\nPrevious Conversation:\n{chat_history}\n\nQuestion: {input}\n{agent_scratchpad}",
          "inputModeration": ""
        },
        "outputAnchors": [
          {
            "id": "xmlAgent_0-output-xmlAgent-XMLAgent|BaseChain|Runnable",
            "name": "xmlAgent",
            "label": "XMLAgent",
            "description": "Agent that is designed for LLMs that are good for reasoning/writing XML (e.g: Anthropic Claude)",
            "type": "XMLAgent | BaseChain | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 477,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": 4451.735047073274,
        "y": 191.84955995995517
      }
    },
    {
      "id": "cohere_0",
      "position": {
        "x": -767.8003103588776,
        "y": -926.3305884998405
      },
      "type": "customNode",
      "data": {
        "id": "cohere_0",
        "label": "Cohere",
        "version": 3,
        "name": "cohere",
        "type": "Cohere",
        "baseClasses": [
          "Cohere",
          "LLM",
          "BaseLLM",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "LLMs",
        "description": "Wrapper around Cohere large language models",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "cohereApi"
            ],
            "id": "cohere_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "command",
            "id": "cohere_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.7,
            "optional": true,
            "id": "cohere_0-input-temperature-number"
          },
          {
            "label": "Max Tokens",
            "name": "maxTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "id": "cohere_0-input-maxTokens-number"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "cohere_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "",
          "modelName": "command-light",
          "temperature": "0.3",
          "maxTokens": ""
        },
        "outputAnchors": [
          {
            "id": "cohere_0-output-cohere-Cohere|LLM|BaseLLM|BaseLanguageModel|Runnable",
            "name": "cohere",
            "label": "Cohere",
            "description": "Wrapper around Cohere large language models",
            "type": "Cohere | LLM | BaseLLM | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 679,
      "selected": false,
      "dragging": false,
      "positionAbsolute": {
        "x": -767.8003103588776,
        "y": -926.3305884998405
      }
    },
    {
      "id": "chatGoogleGenerativeAI_0",
      "position": {
        "x": 2581.854790400921,
        "y": 293.684384755167
      },
      "type": "customNode",
      "data": {
        "id": "chatGoogleGenerativeAI_0",
        "label": "ChatGoogleGenerativeAI",
        "version": 2,
        "name": "chatGoogleGenerativeAI",
        "type": "ChatGoogleGenerativeAI",
        "baseClasses": [
          "ChatGoogleGenerativeAI",
          "LangchainChatGoogleGenerativeAI",
          "BaseChatModel",
          "BaseLanguageModel",
          "Runnable"
        ],
        "category": "Chat Models",
        "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
        "inputParams": [
          {
            "label": "Connect Credential",
            "name": "credential",
            "type": "credential",
            "credentialNames": [
              "googleGenerativeAI"
            ],
            "optional": false,
            "description": "Google Generative AI credential.",
            "id": "chatGoogleGenerativeAI_0-input-credential-credential"
          },
          {
            "label": "Model Name",
            "name": "modelName",
            "type": "asyncOptions",
            "loadMethod": "listModels",
            "default": "gemini-pro",
            "id": "chatGoogleGenerativeAI_0-input-modelName-asyncOptions"
          },
          {
            "label": "Temperature",
            "name": "temperature",
            "type": "number",
            "step": 0.1,
            "default": 0.9,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-temperature-number"
          },
          {
            "label": "Max Output Tokens",
            "name": "maxOutputTokens",
            "type": "number",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-maxOutputTokens-number"
          },
          {
            "label": "Top Probability",
            "name": "topP",
            "type": "number",
            "step": 0.1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topP-number"
          },
          {
            "label": "Top Next Highest Probability Tokens",
            "name": "topK",
            "type": "number",
            "description": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive",
            "step": 1,
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-topK-number"
          },
          {
            "label": "Harm Category",
            "name": "harmCategory",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_attribute_definitions\">official guide</a> on how to use Harm Category",
            "options": [
              {
                "label": "Dangerous",
                "name": "HARM_CATEGORY_DANGEROUS_CONTENT"
              },
              {
                "label": "Harassment",
                "name": "HARM_CATEGORY_HARASSMENT"
              },
              {
                "label": "Hate Speech",
                "name": "HARM_CATEGORY_HATE_SPEECH"
              },
              {
                "label": "Sexually Explicit",
                "name": "HARM_CATEGORY_SEXUALLY_EXPLICIT"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmCategory-multiOptions"
          },
          {
            "label": "Harm Block Threshold",
            "name": "harmBlockThreshold",
            "type": "multiOptions",
            "description": "Refer to <a target=\"_blank\" href=\"https://cloud.google.com/vertex-ai/docs/generative-ai/multimodal/configure-safety-attributes#safety_setting_thresholds\">official guide</a> on how to use Harm Block Threshold",
            "options": [
              {
                "label": "Low and Above",
                "name": "BLOCK_LOW_AND_ABOVE"
              },
              {
                "label": "Medium and Above",
                "name": "BLOCK_MEDIUM_AND_ABOVE"
              },
              {
                "label": "None",
                "name": "BLOCK_NONE"
              },
              {
                "label": "Only High",
                "name": "BLOCK_ONLY_HIGH"
              },
              {
                "label": "Threshold Unspecified",
                "name": "HARM_BLOCK_THRESHOLD_UNSPECIFIED"
              }
            ],
            "optional": true,
            "additionalParams": true,
            "id": "chatGoogleGenerativeAI_0-input-harmBlockThreshold-multiOptions"
          },
          {
            "label": "Allow Image Uploads",
            "name": "allowImageUploads",
            "type": "boolean",
            "description": "Automatically uses vision model when image is being uploaded from chat. Only works with LLMChain, Conversation Chain, ReAct Agent, and Conversational Agent",
            "default": false,
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-allowImageUploads-boolean"
          }
        ],
        "inputAnchors": [
          {
            "label": "Cache",
            "name": "cache",
            "type": "BaseCache",
            "optional": true,
            "id": "chatGoogleGenerativeAI_0-input-cache-BaseCache"
          }
        ],
        "inputs": {
          "cache": "{{redisCache_0.data.instance}}",
          "modelName": "gemini-1.5-pro-latest",
          "temperature": "0.3",
          "maxOutputTokens": "",
          "topP": "",
          "topK": "",
          "harmCategory": "",
          "harmBlockThreshold": "",
          "allowImageUploads": true
        },
        "outputAnchors": [
          {
            "id": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
            "name": "chatGoogleGenerativeAI",
            "label": "ChatGoogleGenerativeAI",
            "description": "Wrapper around Google Gemini large language models that use the Chat endpoint",
            "type": "ChatGoogleGenerativeAI | LangchainChatGoogleGenerativeAI | BaseChatModel | BaseLanguageModel | Runnable"
          }
        ],
        "outputs": {},
        "selected": false
      },
      "width": 300,
      "height": 731,
      "positionAbsolute": {
        "x": 2581.854790400921,
        "y": 293.684384755167
      },
      "selected": false,
      "dragging": false
    }
  ],
  "edges": [
    {
      "source": "vectorStoreToDocument_0",
      "sourceHandle": "vectorStoreToDocument_0-output-text-string|json",
      "target": "chatPromptTemplate_0",
      "targetHandle": "chatPromptTemplate_0-input-promptValues-json",
      "type": "buttonedge",
      "id": "vectorStoreToDocument_0-vectorStoreToDocument_0-output-text-string|json-chatPromptTemplate_0-chatPromptTemplate_0-input-promptValues-json",
      "data": {
        "label": ""
      }
    },
    {
      "source": "promptTemplate_0",
      "sourceHandle": "promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_2",
      "targetHandle": "llmChain_2-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "promptTemplate_0-promptTemplate_0-output-promptTemplate-PromptTemplate|BaseStringPromptTemplate|BasePromptTemplate|Runnable-llmChain_2-llmChain_2-input-prompt-BasePromptTemplate",
      "data": {
        "label": ""
      }
    },
    {
      "source": "llmChain_2",
      "sourceHandle": "llmChain_2-output-outputPrediction-string|json",
      "target": "vectorStoreToDocument_0",
      "targetHandle": "vectorStoreToDocument_0-input-query-string",
      "type": "buttonedge",
      "id": "llmChain_2-llmChain_2-output-outputPrediction-string|json-vectorStoreToDocument_0-vectorStoreToDocument_0-input-query-string",
      "data": {
        "label": ""
      }
    },
    {
      "source": "chatPromptTemplate_0",
      "sourceHandle": "chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-prompt-BasePromptTemplate",
      "type": "buttonedge",
      "id": "chatPromptTemplate_0-chatPromptTemplate_0-output-chatPromptTemplate-ChatPromptTemplate|BaseChatPromptTemplate|BasePromptTemplate|Runnable-llmChain_1-llmChain_1-input-prompt-BasePromptTemplate",
      "data": {
        "label": ""
      }
    },
    {
      "source": "chroma_0",
      "sourceHandle": "chroma_0-output-vectorStore-Chroma|VectorStore",
      "target": "vectorStoreToDocument_0",
      "targetHandle": "vectorStoreToDocument_0-input-vectorStore-VectorStore",
      "type": "buttonedge",
      "id": "chroma_0-chroma_0-output-vectorStore-Chroma|VectorStore-vectorStoreToDocument_0-vectorStoreToDocument_0-input-vectorStore-VectorStore"
    },
    {
      "source": "redisEmbeddingsCache_0",
      "sourceHandle": "redisEmbeddingsCache_0-output-redisEmbeddingsCache-RedisEmbeddingsCache|Embeddings",
      "target": "chroma_0",
      "targetHandle": "chroma_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "redisEmbeddingsCache_0-redisEmbeddingsCache_0-output-redisEmbeddingsCache-RedisEmbeddingsCache|Embeddings-chroma_0-chroma_0-input-embeddings-Embeddings"
    },
    {
      "source": "llmChain_1",
      "sourceHandle": "llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable",
      "target": "chainTool_0",
      "targetHandle": "chainTool_0-input-baseChain-BaseChain",
      "type": "buttonedge",
      "id": "llmChain_1-llmChain_1-output-llmChain-LLMChain|BaseChain|Runnable-chainTool_0-chainTool_0-input-baseChain-BaseChain"
    },
    {
      "source": "googleGenerativeAiEmbeddings_0",
      "sourceHandle": "googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings",
      "target": "redisEmbeddingsCache_0",
      "targetHandle": "redisEmbeddingsCache_0-input-embeddings-Embeddings",
      "type": "buttonedge",
      "id": "googleGenerativeAiEmbeddings_0-googleGenerativeAiEmbeddings_0-output-googleGenerativeAiEmbeddings-GoogleGenerativeAiEmbeddings|Embeddings-redisEmbeddingsCache_0-redisEmbeddingsCache_0-input-embeddings-Embeddings"
    },
    {
      "source": "groqChat_0",
      "sourceHandle": "groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "llmChain_1",
      "targetHandle": "llmChain_1-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "groqChat_0-groqChat_0-output-groqChat-GroqChat|BaseChatModel|BaseLanguageModel|Runnable-llmChain_1-llmChain_1-input-model-BaseLanguageModel"
    },
    {
      "source": "redisCache_1",
      "sourceHandle": "redisCache_1-output-redisCache-RedisCache|BaseCache",
      "target": "groqChat_0",
      "targetHandle": "groqChat_0-input-cache-BaseCache",
      "type": "buttonedge",
      "id": "redisCache_1-redisCache_1-output-redisCache-RedisCache|BaseCache-groqChat_0-groqChat_0-input-cache-BaseCache"
    },
    {
      "source": "cheerioWebScraper_0",
      "sourceHandle": "cheerioWebScraper_0-output-cheerioWebScraper-Document",
      "target": "chroma_0",
      "targetHandle": "chroma_0-input-document-Document",
      "type": "buttonedge",
      "id": "cheerioWebScraper_0-cheerioWebScraper_0-output-cheerioWebScraper-Document-chroma_0-chroma_0-input-document-Document"
    },
    {
      "source": "htmlToMarkdownTextSplitter_0",
      "sourceHandle": "htmlToMarkdownTextSplitter_0-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable",
      "target": "cheerioWebScraper_0",
      "targetHandle": "cheerioWebScraper_0-input-textSplitter-TextSplitter",
      "type": "buttonedge",
      "id": "htmlToMarkdownTextSplitter_0-htmlToMarkdownTextSplitter_0-output-htmlToMarkdownTextSplitter-HtmlToMarkdownTextSplitter|MarkdownTextSplitter|RecursiveCharacterTextSplitter|TextSplitter|BaseDocumentTransformer|Runnable-cheerioWebScraper_0-cheerioWebScraper_0-input-textSplitter-TextSplitter"
    },
    {
      "source": "RedisBackedChatMemory_0",
      "sourceHandle": "RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory",
      "target": "xmlAgent_0",
      "targetHandle": "xmlAgent_0-input-memory-BaseChatMemory",
      "type": "buttonedge",
      "id": "RedisBackedChatMemory_0-RedisBackedChatMemory_0-output-RedisBackedChatMemory-RedisBackedChatMemory|BaseChatMemory|BaseMemory-xmlAgent_0-xmlAgent_0-input-memory-BaseChatMemory"
    },
    {
      "source": "chainTool_0",
      "sourceHandle": "chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable",
      "target": "xmlAgent_0",
      "targetHandle": "xmlAgent_0-input-tools-Tool",
      "type": "buttonedge",
      "id": "chainTool_0-chainTool_0-output-chainTool-ChainTool|DynamicTool|Tool|StructuredTool|Runnable-xmlAgent_0-xmlAgent_0-input-tools-Tool"
    },
    {
      "source": "cohere_0",
      "sourceHandle": "cohere_0-output-cohere-Cohere|LLM|BaseLLM|BaseLanguageModel|Runnable",
      "target": "llmChain_2",
      "targetHandle": "llmChain_2-input-model-BaseLanguageModel",
      "type": "buttonedge",
      "id": "cohere_0-cohere_0-output-cohere-Cohere|LLM|BaseLLM|BaseLanguageModel|Runnable-llmChain_2-llmChain_2-input-model-BaseLanguageModel"
    },
    {
      "source": "redisCache_0",
      "sourceHandle": "redisCache_0-output-redisCache-RedisCache|BaseCache",
      "target": "chatGoogleGenerativeAI_0",
      "targetHandle": "chatGoogleGenerativeAI_0-input-cache-BaseCache",
      "type": "buttonedge",
      "id": "redisCache_0-redisCache_0-output-redisCache-RedisCache|BaseCache-chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-input-cache-BaseCache"
    },
    {
      "source": "chatGoogleGenerativeAI_0",
      "sourceHandle": "chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable",
      "target": "xmlAgent_0",
      "targetHandle": "xmlAgent_0-input-model-BaseChatModel",
      "type": "buttonedge",
      "id": "chatGoogleGenerativeAI_0-chatGoogleGenerativeAI_0-output-chatGoogleGenerativeAI-ChatGoogleGenerativeAI|LangchainChatGoogleGenerativeAI|BaseChatModel|BaseLanguageModel|Runnable-xmlAgent_0-xmlAgent_0-input-model-BaseChatModel"
    }
  ]
}